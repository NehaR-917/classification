{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94aad865",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import tensorflow \n",
    "import scipy\n",
    "\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Dropout, BatchNormalization, Input, AveragePooling2D,Activation\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.applications.vgg19 import VGG19\n",
    "from tensorflow.keras.applications.vgg19 import preprocess_input\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.preprocessing import image, image_dataset_from_directory\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential,Model\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2cd5ef0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = './dataset/train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a1373e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "img_height = 256\n",
    "img_width = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "443e9981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5121 files belonging to 4 classes.\n",
      "Using 4097 files for training.\n"
     ]
    }
   ],
   "source": [
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  train_path,\n",
    "  validation_split=0.2,\n",
    "  subset=\"training\",\n",
    "  seed=123,\n",
    "  label_mode='categorical',\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c61f5987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5121 files belonging to 4 classes.\n",
      "Using 1024 files for validation.\n"
     ]
    }
   ],
   "source": [
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  train_path,\n",
    "  validation_split=0.2,\n",
    "  subset=\"validation\",\n",
    "  seed=123,\n",
    "  label_mode='categorical',\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f022d85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dcd8449e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rn = ResNet50(input_shape=(256,256,3), weights='imagenet', include_top=False)\n",
    "for layer in rn.layers:\n",
    "    layer.trainable = False\n",
    "x = Flatten()(rn.output)\n",
    "\n",
    "prediction = Dense(4, activation='softmax')(x)\n",
    "\n",
    "modelrn = Model(inputs=rn.input, outputs=prediction)\n",
    "\n",
    "modelrn.compile(optimizer='adam',\n",
    "loss=tensorflow.losses.CategoricalCrossentropy(),\n",
    "metrics=[keras.metrics.AUC(name='auc')])\n",
    "\n",
    "callback = keras.callbacks.EarlyStopping(monitor='val_loss',patience=8,restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cb8d0a3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "513/513 [==============================] - 144s 216ms/step - loss: 9.2019 - auc: 0.7647 - val_loss: 5.0389 - val_auc: 0.8392\n",
      "Epoch 2/15\n",
      "513/513 [==============================] - 107s 208ms/step - loss: 3.3542 - auc: 0.9008 - val_loss: 3.1306 - val_auc: 0.8955\n",
      "Epoch 3/15\n",
      "513/513 [==============================] - 103s 201ms/step - loss: 1.9856 - auc: 0.9359 - val_loss: 4.9754 - val_auc: 0.8891\n",
      "Epoch 4/15\n",
      "513/513 [==============================] - 103s 200ms/step - loss: 1.6901 - auc: 0.9477 - val_loss: 2.0942 - val_auc: 0.9290\n",
      "Epoch 5/15\n",
      "513/513 [==============================] - 102s 200ms/step - loss: 1.7769 - auc: 0.9529 - val_loss: 5.7951 - val_auc: 0.8612\n",
      "Epoch 6/15\n",
      "513/513 [==============================] - 164s 320ms/step - loss: 1.2730 - auc: 0.9664 - val_loss: 4.5368 - val_auc: 0.9106\n",
      "Epoch 7/15\n",
      "513/513 [==============================] - 102s 199ms/step - loss: 1.3135 - auc: 0.9666 - val_loss: 5.7759 - val_auc: 0.8866\n",
      "Epoch 8/15\n",
      "513/513 [==============================] - 147s 286ms/step - loss: 1.7087 - auc: 0.9655 - val_loss: 4.2213 - val_auc: 0.9112\n",
      "Epoch 9/15\n",
      "513/513 [==============================] - 102s 200ms/step - loss: 0.6784 - auc: 0.9812 - val_loss: 8.2481 - val_auc: 0.8575\n",
      "Epoch 10/15\n",
      "513/513 [==============================] - 657s 1s/step - loss: 0.8472 - auc: 0.9780 - val_loss: 3.6008 - val_auc: 0.9194\n",
      "Epoch 11/15\n",
      "513/513 [==============================] - 101s 197ms/step - loss: 1.2472 - auc: 0.9691 - val_loss: 3.1676 - val_auc: 0.9399\n",
      "Epoch 12/15\n",
      "513/513 [==============================] - 102s 199ms/step - loss: 1.5047 - auc: 0.9728 - val_loss: 14.9142 - val_auc: 0.8452\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f37d7cf760>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelrn.fit(train_ds, epochs=15, validation_data=val_ds,callbacks=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "35ca894a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128/128 [==============================] - 21s 161ms/step - loss: 2.0942 - auc: 0.9290\n",
      "Accuracy:  0.928955614566803\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = modelrn.evaluate(val_ds)\n",
    "print(\"Accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6878fbfa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
